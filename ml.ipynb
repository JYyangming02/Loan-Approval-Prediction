{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanDataAnalyzer:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "    \n",
    "    def analyze_data(self):\n",
    "        self.home_ownership = self.df[\"person_home_ownership\"].value_counts()\n",
    "        self.loan_intent = self.df[\"loan_intent\"].value_counts()\n",
    "        self.loan_grade = self.df[\"loan_grade\"].value_counts()\n",
    "        self.cb_person_default_on_file = self.df[\"cb_person_default_on_file\"].value_counts()\n",
    "        \n",
    "        self.unique_home_ownership = self.df[\"person_home_ownership\"].unique()\n",
    "        self.unique_loan_intent = self.df[\"loan_intent\"].unique()\n",
    "        \n",
    "        return self.get_summary()\n",
    "\n",
    "    def get_summary(self):\n",
    "        summary = {\n",
    "            \"Home Ownership\": self.home_ownership,\n",
    "            \"Loan Intent\": self.loan_intent,\n",
    "            \"Loan Grade\": self.loan_grade,\n",
    "            \"Default Status\": self.cb_person_default_on_file,\n",
    "            \"Unique Home Ownership\": self.unique_home_ownership,\n",
    "            \"Unique Loan Intent\": self.unique_loan_intent\n",
    "        }\n",
    "        return summary\n",
    "    \n",
    "    def plot_data(self):\n",
    "        plt.figure(figsize=(18, 9))\n",
    "        plt.subplot(1, 4, 1)\n",
    "        self.home_ownership.plot(kind='bar')\n",
    "        plt.title('Home Ownership')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        self.loan_intent.plot(kind='bar')\n",
    "        plt.title('Loan Intent')\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        self.loan_grade.plot(kind='bar')\n",
    "        plt.title('Loan Grade')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        self.cb_person_default_on_file.plot(kind='bar')\n",
    "        plt.title('Default Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analyzer = LoanDataAnalyzer(train_df)\n",
    "train_summary = train_analyzer.analyze_data()\n",
    "\n",
    "test_analyzer = LoanDataAnalyzer(test_df)\n",
    "test_summary = test_analyzer.analyze_data()\n",
    "\n",
    "print(\"Train Data Summary:\")\n",
    "print(train_summary)\n",
    "print(\"\\nTest Data Summary:\")\n",
    "print(test_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analyzer.plot_data()\n",
    "test_analyzer.plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Categorical Variable\n",
    "- one-hot encoding\n",
    "- lable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_target = train_df[\"loan_status\"]\n",
    "train_df_features = train_df.drop([\"loan_status\", \"id\"], axis=1)\n",
    "\n",
    "test_df_features = test_df.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanFeatureEncoder:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.oh_encoder = OneHotEncoder(sparse_output=False)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.encoded_features = None\n",
    "\n",
    "    def encode_features(self, oh_features, grade_ordering, default_ordering):\n",
    "        # one-hot encode the categorical features\n",
    "        features_encoded = self.oh_encoder.fit_transform(self.df[oh_features])\n",
    "        encoded_df = pd.DataFrame(features_encoded, columns=self.oh_encoder.get_feature_names_out(oh_features))\n",
    "\n",
    "        self.df.drop(oh_features, axis=1, inplace=True)\n",
    "        self.df = pd.concat([self.df, encoded_df], axis=1)\n",
    "\n",
    "        # label encode the ordinal features\n",
    "        self.df[\"loan_grade\"] = pd.Categorical(self.df[\"loan_grade\"], categories=grade_ordering, ordered=True)\n",
    "        self.df[\"loan_grade\"] = self.label_encoder.fit_transform(self.df[\"loan_grade\"])\n",
    "\n",
    "        self.df[\"cb_person_default_on_file\"] = pd.Categorical(self.df[\"cb_person_default_on_file\"], categories=default_ordering, ordered=True)\n",
    "        self.df[\"cb_person_default_on_file\"] = self.label_encoder.fit_transform(self.df[\"cb_person_default_on_file\"])\n",
    "\n",
    "        self.encoded_features = self.df\n",
    "        return self.encoded_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_features = [\"person_home_ownership\", \"loan_intent\"]\n",
    "grade_ordering = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "default_ordering = ['N', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder = LoanFeatureEncoder(train_df_features)\n",
    "train_encoded_df_feature = train_encoder.encode_features(oh_features, grade_ordering, default_ordering)\n",
    "print(train_encoded_df_feature.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder = LoanFeatureEncoder(test_df_features)\n",
    "test_encoded_df_feature = test_encoder.encode_features(oh_features, grade_ordering, default_ordering)\n",
    "print(test_encoded_df_feature.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, target_train, target_test = train_test_split(train_encoded_df_feature, train_df_target, \n",
    "                                                                          test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "feature_train, target_train = smote.fit_resample(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "def grid_search(model, param, feature_train, target_train):\n",
    "    grid_search = GridSearchCV(model, param, scoring='roc_auc',cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(feature_train, target_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric = 'auc',random_state=42)\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "grid_search(xgb, xgb_param_grid, feature_train=train_encoded_df_feature, target_train=train_df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- xgboost {'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(eval_metric='AUC', random_state=42)\n",
    "cat_param_grid = {\n",
    "    'depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'iterations': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bylevel': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search(cat, cat_param_grid, feature_train=train_encoded_df_feature, target_train=train_df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(objective='binary', eval_metric='auc',random_state=42)\n",
    "lgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "grid_search(lgb, lgb_param_grid, feature_train=train_encoded_df_feature, target_train=train_df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- catboost{'colsample_bylevel': 1.0, 'depth': 3, 'iterations': 300, 'learning_rate': 0.5, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "param = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.3,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', \n",
    "                    eval_metric='auc', \n",
    "                    random_state=42, \n",
    "                    **param)\n",
    "\n",
    "XGB_model = xgb.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost model\n",
    "best_params = {\n",
    "    'depth': 3,\n",
    "    'learning_rate': 0.5,\n",
    "    'iterations': 300,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bylevel': 1.0\n",
    "}\n",
    "cat = CatBoostClassifier(eval_metric='AUC', random_state=42, verbose=10,**best_params)\n",
    "\n",
    "CAT_model = cat.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "lgb = LGBMClassifier(objective='binary', random_state=42)\n",
    "LGB_model = lgb.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_model = LGBMClassifier(objective='binary', random_state=42)\n",
    "LGB_model.fit(feature_train, target_train)\n",
    "lgb_pred_train = cross_val_predict(LGB_model, feature_train, target_train, cv=5, method='predict_proba')[:, 1]\n",
    "\n",
    "xgb_param = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.3,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "XGB_model = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=42, **xgb_param)\n",
    "XGB_model.fit(feature_train, target_train)\n",
    "xgb_pred_train = cross_val_predict(XGB_model, feature_train, target_train, cv=5, method='predict_proba')[:, 1]\n",
    "\n",
    "cat_params = {\n",
    "    'depth': 3,\n",
    "    'learning_rate': 0.5,\n",
    "    'iterations': 300,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bylevel': 1.0\n",
    "}\n",
    "CAT_model = CatBoostClassifier(eval_metric='AUC', random_state=42, verbose=10,**cat_params)\n",
    "CAT_model.fit(feature_train, target_train)\n",
    "cat_pred_train = cross_val_predict(CAT_model, feature_train, target_train, cv=5, method='predict_proba')[:, 1]\n",
    "\n",
    "stacked_train = np.column_stack((lgb_pred_train, cat_pred_train, xgb_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = LogisticRegression(random_state=42)\n",
    "stacked_model.fit(stacked_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the valid data\n",
    "rf_pred_test = LGB_model.predict_proba(feature_test)[:, 1]\n",
    "xgb_pred_test = XGB_model.predict_proba(feature_test)[:, 1]\n",
    "cat_pred_test = CAT_model.predict_proba(feature_test)[:, 1]\n",
    "\n",
    "stacked_test = np.column_stack((rf_pred_test, cat_pred_test, xgb_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Model\n",
    "- Hard Voting\n",
    "- Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.3,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', \n",
    "                    eval_metric='auc', \n",
    "                    random_state=42, \n",
    "                    **xgb_param)\n",
    "\n",
    "cat_params = {\n",
    "    'depth': 3,\n",
    "    'learning_rate': 0.5,\n",
    "    'iterations': 300,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bylevel': 1.0\n",
    "}\n",
    "cat = CatBoostClassifier(eval_metric='AUC', random_state=42, verbose=10,**cat_params)\n",
    "\n",
    "lgb = LGBMClassifier(objective='binary', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard voting\n",
    "hard_voting = VotingClassifier(estimators=[('xgb', xgb), ('cat', cat), ('lgb', lgb)], voting='hard')\n",
    "hard_voting.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft voting\n",
    "soft_voting = VotingClassifier(estimators=[('xgb', xgb), ('cat', cat), ('lgb', lgb)], voting='soft')\n",
    "soft_voting.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, feature_test, target_test):\n",
    "        self.model = model\n",
    "        self.feature_test = feature_test\n",
    "        self.target_test = target_test\n",
    "        self.predictions = None\n",
    "        self.target_prob = None\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.predictions = self.model.predict(self.feature_test)\n",
    "        self.target_prob = self.model.predict_proba(self.feature_test)[:, 1]\n",
    "\n",
    "        accuracy = accuracy_score(self.target_test, self.predictions)\n",
    "        \n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(classification_report(self.target_test, self.predictions))\n",
    "        print(confusion_matrix(self.target_test, self.predictions))\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        # roc curve\n",
    "        fpr, tpr, _ = roc_curve(self.target_test, self.target_prob)\n",
    "        roc_auc = roc_auc_score(self.target_test, self.target_prob)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_confusion_matrix(self):\n",
    "        # confusion matrix\n",
    "        cm = confusion_matrix(self.target_test, self.predictions)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluator = ModelEvaluator(soft_voting, feature_test, target_test)\n",
    "train_evaluator.evaluate()\n",
    "train_evaluator.plot_roc_curve()\n",
    "train_evaluator.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluator = ModelEvaluator(stacked_model, stacked_test, target_test)\n",
    "train_evaluator.evaluate()\n",
    "train_evaluator.plot_roc_curve()\n",
    "train_evaluator.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the test data\n",
    "rf_pred_test = LGB_model.predict_proba(test_encoded_df_feature)[:, 1]\n",
    "xgb_pred_test = XGB_model.predict_proba(test_encoded_df_feature)[:, 1]\n",
    "cat_pred_test = CAT_model.predict_proba(test_encoded_df_feature)[:, 1]\n",
    "\n",
    "stacked_test_data = np.column_stack((rf_pred_test, cat_pred_test, xgb_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = soft_voting.predict(test_encoded_df_feature)\n",
    "# test_pred = stacked_model.predict(stacked_test_data)\n",
    "test_df[\"loan_status\"] = test_pred\n",
    "\n",
    "test_df.to_csv('./output/soft_predictions.csv', columns=[\"id\", \"loan_status\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
